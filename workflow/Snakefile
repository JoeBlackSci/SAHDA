# Mycogenomics Genome Assembly and Query Workflow
# Workflow to identify and compare target genes within small haplotype genomes.
# J. Blackwell, M. McDonald.
# University of Birmingham

###############################################################################
### Initalisation ###
###############################################################################

# Set the workflow configuaration file (not currently in use)
# configfile: "config/config.yml"

# Setting variables
## Global variables

### Set samples
# Each set of samples in their own folder with a fasta adapter file
# if config["samples"]:
#     samples = config["samples"]
# else:
#     from os import listdir

samples = ["SRR3740251", "WAI1848_L001"]
queries = ["testquery"]

## Trimmomatic parametres
TRIMMOMATIC_OPTIONS = ["LEADING:5 TRAILING:5 SLIDINGWINDOW:4:15 MINLEN:45"]



###############################################################################
### Target Rules ###
###############################################################################
rule target:
    input:
        # expand("results/01_trim/{sample}_trimmed_1P.fastq", sample=samples)
        # expand("results/02_assemble/{sample}_assembled/contigs.fasta", sample=samples),
        # expand("results/03_blastdb/{sample}_blastdb/{sample}_assembly.fasta", sample=samples),
        expand("results/04_search/{query}/{query}_{sample}.txt", query=queries, sample=samples)

###############################################################################
### Workflow Rules ###
###############################################################################

# Requires Java permission (important for clusters?)
rule trimmomatic_trim:
    input:
        R1="resources/{sample}_R1.fastq.gz",
        R2="resources/{sample}_R2.fastq.gz",
        adapters="resources/adapters.fasta"
    output:
        "results/01_trim/{sample}_trimmed_1P.fastq",
        "results/01_trim/{sample}_trimmed_1U.fastq",
        "results/01_trim/{sample}_trimmed_2P.fastq",
        "results/01_trim/{sample}_trimmed_2U.fastq"
    params:
        baseout="results/01_trim/{sample}_trimmed.fastq",
        adapt_op=":2:30:10",
        trim_op=TRIMMOMATIC_OPTIONS
        # Can add in options here from a lsit specified in config.
    conda:
        "envs/env_trimmomatic.yml"
    log:
        "logs/01_trim/{sample}.log"
    shell:
        "trimmomatic PE " # Core command
        "{input.R1} {input.R2} " # Inputs
        "-baseout {params.baseout} " # Output flag
        "ILLUMINACLIP:{input.adapters}{params.adapt_op} " # adapter sequence and options
        "{params.trim_op} " # Options
        "2> {log}" # log output

# provide in order of input size?
# any extra parametres to include?
# need to append the unpaired reads?
rule spades_assembly:
    input:
        P1="results/01_trim/{sample}_trimmed_1P.fastq",
        P2="results/01_trim/{sample}_trimmed_2P.fastq",
        U1="results/01_trim/{sample}_trimmed_1U.fastq",
        U2="results/01_trim/{sample}_trimmed_2U.fastq"
    output:
        "results/02_assemble/{sample}_assembled/contigs.fasta"
    params:
        "results/02_assemble/{sample}_assembled/"
    conda:
        # not latest version but no major changes that impact the workflow
        "envs/env_spades.yml"
    log:
        "logs/02_assemble/{sample}.log"
    shell:
        "spades.py " # Core command
        "--pe1-1 {input.P1} --pe1-2 {input.P2} " # Paired foward and reverse reads
        "--pe1-s {input.U1} --pe1-s {input.U2} " # Unpaired forward and reverse reads
        "-o {params} " # output directory
        "2> {log}" # log

# rename each contig to have a unique identifier for retreval?
# or is it enough that each will be in its own db?
# Maybe best practice to split this into two steps:
# 1. move fasta file
# 2. index with makedb
# Directory here. could be replaced with pram to define folder and have output as a specified file
rule blast_mkblastdb:
    input:
        "results/02_assemble/{sample}_assembled/contigs.fasta"
    output:
        dbdir=directory("results/03_blastdb/{sample}_blastdb/"),
        assembly="results/03_blastdb/{sample}_blastdb/{sample}_assembly.fasta"
    params:
        "results/03_blastdb/{sample}_blastdb/{sample}_assembly"
    conda:
        "envs/env_blast_plus.yml"
    log:
        makedb="logs/03_blastdb/{sample}_makedb.log",
        cpfasta="logs/03_blastdb/{sample}_cpfasta.log"
    shell:
        "makeblastdb " # Core command
        "-in {input} " # Input files
        "-dbtype nucl " # Database Options
        "-out {params} " # output directory
        "-logfile {log.makedb} " # log
        "; " # next shell command
        "cp {input} {output.assembly} " # copy fasta assembly
        "2> {log.cpfasta}" # log

# Currently working for just a lingle query
# More work needed for scalbility here
# Output should be csv?
rule blast_search:
    input:
        query="resources/query/{query}.fasta",
        blastdb="results/03_blastdb/{sample}_blastdb/"
    output:
        "results/04_search/{query}/{query}_{sample}.txt"
    params:
        "results/03_blastdb/{sample}_blastdb/{sample}_assembly"
    conda:
        "envs/env_blast_plus.yml"
    log:
        "logs/04_search/{query}_{sample}_search.log"
    shell:
        "blastn " # Core command
        "-db {params} " # Database
        "-query {input.query} " # query
        "-out {output} " # output file
        "2> {log}" # log

rule blasttogff:
    input:
        inFasta="resources/query/{query}.fasta",
        refFasta="results/03_blastdb/{sample}_blastdb/{sample}_assembly.fasta",
        inBlast="results/04_search/{query}/{query}_{sample}.txt"
    output:
        outGff="results/05_retrieve/{query}_{sample}_retrieved.gff",
        outFasta="results/05_retrieve/{query}_{sample}_retrieved.fasta"
    params:
        centCover="50"
    conda:
        "envs/env_biopython.yml"
    log:
        "logs/05_retrieve/{query}_{sample}_retrieve.log"
    shell:
        "BLASTtoGFF.py " # Core command
        "-i {input.inFasta} " # Query fasta
        "-r {input.refFasta} " # Denovo assembly
        "-b {input.inBlast} " # Blast search result
        "-g {output.outGff} " # gff output
        "-o {output.outFasta} " # retreived sequence
        "-p {params.centCover} " # minimum percent result coverage
        "2> {log}" # log

# rule multiple_alignment:
