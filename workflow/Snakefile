# Mycogenomics Genome Assembly and Query Workflow
# Workflow to identify and compare target genes within small haplotype genomes.
# J. Blackwell, M. McDonald.
# University of Birmingham

#####################
### Initalisation ###
#####################

# Set the workflow configuaration file
configfile: "config/config.yml"

# Setting workflow settings
samples = config["Samples"]
queries = config["Queries"]

# Trimmomatic settings
adapters = config["Adapter_file"]
ADAPTER_OPTIONS = config["Adapter_options"]
TRIMMOMATIC_OPTIONS = config["Trimmomatic_options"]

# Check lists
print(samples)
print(queries)
print(adapters)
print(TRIMMOMATIC_OPTIONS)

####################
### Target Rules ###
####################
rule target_trim:
    input:
        expand("results/01_trim/{sample}_trimmed_1P.fastq", sample=samples)

rule target_assemble:
    input:
        expand("results/02_assemble/{sample}_assembled/contigs.fasta", sample=samples)

rule target_blastdb:
    input:
        expand("results/03_blastdb/{sample}_blastdb/{sample}_assembly.fasta", sample=samples)

rule target_search:
    input:
        expand("results/04_search/{query}/{query}_{sample}.txt", query=queries, sample=samples)

rule target_retreive:
    input:
        expand("results/05_retrieve/{query}/{query}_{sample}_retrieved.fasta", query=queries, sample=samples)

rule target_align:
    input:
        expand("results/07_align/{query}_aligned.fasta", query=queries)

######################
### Workflow Rules ###
######################

rule file_append:
    input:
        L1_R1="resources/reads/{sample}_L001_R1.fastq.gz",
        L1_R2="resources/reads/{sample}_L001_R2.fastq.gz",
        L2_R1="resources/reads/{sample}_L002_R1.fastq.gz",
        L2_R2="resources/reads/{sample}_L002_R2.fastq.gz"
    output:
        R1="resources/00_append/{sample}_R1.fastq.gz",
        R2="resources/00_append/{sample}_R2.fastq.gz"
    log:
        "logs/00_append/{sample}.log"
    shell:
        "cat {input.L2_R1} {input.L1_R1} > {output.R1} "
        "; "
        "cat {input.L2_R2} {input.L1_R2} > {output.R2}"


# Requires Java permission (important for clusters?)
# Need to switch to the java command
rule trimmomatic_trim:
    input:
        R1="resources/reads/{sample}_R1.fastq.gz",
        R2="resources/reads/{sample}_R2.fastq.gz",
        adapters=expand("resources/adapters/{adapter}", adapter=adapters)
    output:
        "results/01_trim/{sample}_trimmed_1P.fastq",
        "results/01_trim/{sample}_trimmed_1U.fastq",
        "results/01_trim/{sample}_trimmed_2P.fastq",
        "results/01_trim/{sample}_trimmed_2U.fastq"
    params:
        baseout="results/01_trim/{sample}_trimmed.fastq",
        adapt_op=ADAPTER_OPTIONS,
        trim_op=TRIMMOMATIC_OPTIONS
    conda:
        "envs/env_trimmomatic.yml"
    log:
        "logs/01_trim/{sample}.log"
    shell:
        "trimmomatic PE " # Core command
        "{input.R1} {input.R2} " # Inputs
        "-baseout {params.baseout} " # Output flag
        "ILLUMINACLIP:{input.adapters}{params.adapt_op} " # adapter sequence and options
        "{params.trim_op} " # Options
        "2> {log}" # log output

rule trimmomatic_trim_alt:
    input:
        R1="resources/00_append/{sample}_R1.fastq.gz",
        R2="resources/00_append/{sample}_R2.fastq.gz",
        adapters=expand("resources/adapters/{adapter}", adapter=adapters)
    output:
        "results/01_trim/{sample}_trimmed_1P.fastq",
        "results/01_trim/{sample}_trimmed_1U.fastq",
        "results/01_trim/{sample}_trimmed_2P.fastq",
        "results/01_trim/{sample}_trimmed_2U.fastq"
    params:
        baseout="results/01_trim/{sample}_trimmed.fastq",
        adapt_op=ADAPTER_OPTIONS,
        trim_op=TRIMMOMATIC_OPTIONS
    conda:
        "envs/env_trimmomatic.yml"
    log:
        "logs/01_trim/{sample}.log"
    shell:
        "trimmomatic PE " # Core command
        "{input.R1} {input.R2} " # Inputs
        "-baseout {params.baseout} " # Output flag
        "ILLUMINACLIP:{input.adapters}{params.adapt_op} " # adapter sequence and options
        "{params.trim_op} " # Options
        "2> {log}" # log output


# provide in order of input size?
# any extra parametres to include?
# need to append the unpaired reads?
rule spades_assembly:
    input:
        P1="results/01_trim/{sample}_trimmed_1P.fastq",
        P2="results/01_trim/{sample}_trimmed_2P.fastq",
        U1="results/01_trim/{sample}_trimmed_1U.fastq",
        U2="results/01_trim/{sample}_trimmed_2U.fastq"
    output:
        "results/02_assemble/{sample}_assembled/contigs.fasta"
    params:
        "results/02_assemble/{sample}_assembled/"
    conda:
        # not latest version but no major changes that impact the workflow
        "envs/env_spades.yml"
    log:
        "logs/02_assemble/{sample}.log"
    shell:
        "spades.py " # Core command
        "--pe1-1 {input.P1} --pe1-2 {input.P2} " # Paired foward and reverse reads
        "--pe1-s {input.U1} --pe1-s {input.U2} " # Unpaired forward and reverse reads
        "-o {params} " # output directory
        "2> {log}" # log

# rename each contig to have a unique identifier for retreval?
# or is it enough that each will be in its own db?
# Maybe best practice to split this into two steps:
# 1. move fasta file
# 2. index with makedb
# Directory here. could be replaced with pram to define folder and have output as a specified file
rule blast_mkblastdb:
    input:
        "results/02_assemble/{sample}_assembled/contigs.fasta"
    output:
        dbdir=directory("results/03_blastdb/{sample}_blastdb/"),
        assembly="results/03_blastdb/{sample}_blastdb/{sample}_assembly.fasta"
    params:
        "results/03_blastdb/{sample}_blastdb/{sample}_assembly"
    conda:
        "envs/env_blast_plus.yml"
    log:
        makedb="logs/03_blastdb/{sample}_makedb.log",
        cpfasta="logs/03_blastdb/{sample}_cpfasta.log"
    shell:
        "makeblastdb " # Core command
        "-in {input} " # Input files
        "-dbtype nucl " # Database Options
        "-out {params} " # output directory
        "-logfile {log.makedb} " # log
        "; " # next shell command
        "cp {input} {output.assembly} " # copy fasta assembly
        "2> {log.cpfasta}" # log

# Currently working for just a single query
# What if there is no results?
rule blast_search:
    input:
        query="resources/query/{query}.fasta",
        blastdb="results/03_blastdb/{sample}_blastdb/"
    output:
        "results/04_search/{query}/{query}_{sample}.txt"
    params:
        blastdb="results/03_blastdb/{sample}_blastdb/{sample}_assembly",
        format="\"6 qseqid qlen sseqid sstart send qstart qend evalue bitscore length pident \""
    conda:
        "envs/env_blast_plus.yml"
    log:
        "logs/04_search/{query}_{sample}_search.log"
    shell:
        "blastn " # Core command
        "-db {params.blastdb} " # Database
        "-query {input.query} " # query
        "-outfmt {params.format} " # format
        "-out {output} " # output file
        "2> {log}" # log

rule blasttogff:
    input:
        inFasta="resources/query/{query}.fasta",
        refFasta="results/03_blastdb/{sample}_blastdb/{sample}_assembly.fasta",
        inBlast="results/04_search/{query}/{query}_{sample}.txt"
    output:
        outGff="results/05_retrieve/{query}/{query}_{sample}_retrieved.gff",
        outFasta="results/05_retrieve/{query}/{query}_{sample}_retrieved.fasta"
    params:
        centCover="50"
    conda:
        "envs/env_biopython.yml"
    log:
        "logs/05_retrieve/{query}_{sample}_retrieve.log"
    shell:
        "workflow/scripts/BLASTtoGFF.py " # Core command
        "-i {input.inFasta} " # Query fasta
        "-r {input.refFasta} " # Denovo assembly
        "-b {input.inBlast} " # Blast search result
        "-g {output.outGff} " # gff output
        "-o {output.outFasta} " # retreived sequence
        "-p {params.centCover} " # minimum percent result coverage
        "2> {log}" # log


rule target_condense:
    input:
        "results/05_retrieve/{query}"
    output:
        "results/06_combine/{query}_all.fasta"
    log:
        "logs/06_combine/{query}_align.log"
    shell:
        "cat {input}/*_retrieved.fasta > {output}"

# rule multiple_alignment:
# Comparison: doi: 10.1186/1748-7188-9-4
# Chose MAFFT for reasons of accurary, recently increased speed and documentation
# Got to think about inputs

rule mafft_align:
    input:
        "results/06_combine/{query}_all.fasta"
    output:
        "results/07_align/{query}_aligned.fasta"
    log:
        "logs/07_align/{query}_align.log"
    conda:
        "envs/env_mafft.yml"
    shell:
        "mafft {input} > {output} "
        "2> {log}"


# https://snakemake.readthedocs.io/en/stable/project_info/faq.html#how-do-i-run-my-rule-on-all-files-of-a-certain-directory
