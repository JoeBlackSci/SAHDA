{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordered-curve",
   "metadata": {},
   "source": [
    "Mycogenomics Genome Assembly and Query Workflow Lab Book\n",
    "========================================================\n",
    "> **Author:** Joseph Blackwell   \n",
    "> **Year:** 2020  \n",
    "> **Overview:** Lab notebook detailing the development of the mycogenomic genome assembly and query workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-weapon",
   "metadata": {},
   "source": [
    "## Project Results\n",
    "\n",
    "<img align=\"left\" width=\"100\" src=\"ZPic.png\" style=\"padding-right: 10px\">  \n",
    "\n",
    "[![Version](https://img.shields.io/badge/Version-0.3.0-red)](https://github.com/JoeBlackSci/genome_assembly_mp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-holder",
   "metadata": {},
   "source": [
    "## Resources\n",
    "### Tutorials\n",
    "[Hadrien Gourle](https://www.hadriengourle.com/tutorials/) - Bioinformatics teacher for Swedeish AgSci Uni  \n",
    "[Data Carpentry](https://datacarpentry.org/lessons/#genomics-workshop) - Data science and wrangling   \n",
    "[Software Carpentry](https://software-carpentry.org/) - Computer science and programming   \n",
    "[Library Carpentry](https://librarycarpentry.org/) - Data structures and navigation  \n",
    "[HPC Carpentry](https://www.hpc-carpentry.org/) - High Performance Computing  \n",
    "[HPC Carpentry Snakemake](https://hpc-carpentry.github.io/hpc-python/) - Snakemake tutorial  \n",
    "[Biostars Handbook](https://www.biostarhandbook.com/) - Biostar handbook  \n",
    "[Bioinformatics Workbook](https://bioinformaticsworkbook.org/#gsc.tab=0) - Bioinf workbook  \n",
    "[Laconic CompSci](https://laconicml.com/computer-science-curriculum-youtube-videos/) - Free computer science course  \n",
    "[WDSS Python Course](https://www.youtube.com/c/WarwickDataScienceSociety/playlists) - Warwick Data Science Soc youtube courses  \n",
    "[Oregon Uni Comp Bio Course](https://open.oregonstate.education/computationalbiology/chapter/command-line-blast/)   \n",
    "[MIT open education](https://ocw.mit.edu/)  \n",
    "### Documentation\n",
    "[![Snakemake](https://img.shields.io/badge/snakemake-â‰¥5.6.0-brightgreen.svg?style=flat)](https://snakemake.readthedocs.io)  \n",
    "[![Conda](https://img.shields.io/badge/conda-4.9.2-brightgreen.svg?style=flat)](https://docs.conda.io/en/latest/)  \n",
    "[trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic)  \n",
    "[SPAdes](https://cab.spbu.ru/software/spades/)  \n",
    "[BLAST Plus](https://www.ncbi.nlm.nih.gov/books/NBK279690/)  \n",
    "[Biopython](https://biopython.org/wiki/Documentation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-shelter",
   "metadata": {},
   "source": [
    "## 20-01-2020\n",
    "\n",
    "- found paied end fastq files to practice on while megan uploads the data for this project.\n",
    "> source: https://www.hadriengourle.com/tutorials/qc/  \n",
    "> **Looks like a good place to go for tutorials in the future**\n",
    "- setup the workflow and initalised the github: https://github.com/JoeBlackSci/genome_assembly_mp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-egyptian",
   "metadata": {},
   "source": [
    "## 21-01-2020\n",
    "\n",
    "- Downloaded paired fastq file for testing.\n",
    "- Worked out a system to automatically import the contents of a directory foulder.\n",
    "    - Use regular expression or wildcard search to generate a list of wildcard keys for expansion or file renaming.\n",
    "    - Alternative: have a script that generates the config file.\n",
    "    - Alternative: Include a conditional statement in the rule imput that seporates the file based on name format.\n",
    "        - Could potentially also include a what quality score system is used.\n",
    "    - Alternative: Set wildcards to be naming convention agnostic.\n",
    "        - If possible.\n",
    "    - Bad alternative: Rename files to same naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minimal-thriller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCES: ['SRR957824_500K_R1.fastq', 'SRR957824_500K_R2.fastq', '.gitignore', 'adapters.fasta']\n",
      "FIELDS: ['SRR957824', '500K', 'R1.fastq', 'SRR957824', '500K', 'R2.fastq', '.gitignore', 'adapters.fasta']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "RESOURCES = listdir(\"../snake_test/resources/\")\n",
    "\n",
    "print(\"RESOURCES:\", RESOURCES)\n",
    "\n",
    "FIELDS = \"_\".join(RESOURCES).split('_')\n",
    "\n",
    "print(\"FIELDS:\", FIELDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-league",
   "metadata": {},
   "source": [
    "##\n",
    "- Managed to get the first step working for a specific instance.\n",
    "    - Used the trimmomatic `-baseout` flag to generate output files.\n",
    "        - This could complicate inputs\n",
    "- Would like to convert files to a unified naming scheme for ease of identification. \n",
    "    - Don't touch the raw data!\n",
    "    - Better to do this during a transformation step or on a dedicated renaming step?\n",
    "    - python / bash (snakemake step / seporate script / snakemake initalization)\n",
    "- described the conda/mamba/snakemake enviroment that is required for correct snakemake installation for the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mounting",
   "metadata": {},
   "source": [
    "## 22-01-2020\n",
    "- Implemnted the SPAdes command\n",
    "- New idea for the file name problem\n",
    "    - new rule for each naming file type. \n",
    "    - Also need to consider adapter files.\n",
    "\n",
    "```python \n",
    "<sample_name>_<direction>.fastq.gz\n",
    "    SRR*******_R*.fastq.gz\n",
    "\n",
    "<sample_name>_<lane>_<direction>.fastq.gz\n",
    "    WAI****_L***_R*.fastq.gz\n",
    "\n",
    "```\n",
    "- Began reading of reproducable science papers (Get zotero to sync)\n",
    "\n",
    "### Jobs for next week\n",
    "- Which adaptors for Trimmomatic\n",
    "- Get zotero to sync\n",
    "- BLAST+ implementation \n",
    "    - for local bast database and query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-generator",
   "metadata": {},
   "source": [
    "## 25-01-2020\n",
    "- BLAST+ makedb integrated into pipeline\n",
    "    - Happy with this \n",
    "- BLAST+ query integrated for multiple queries\n",
    "    - first implementation needs to be finessed\n",
    "    - Need to know what format queries need to be in\n",
    "    - Need to know what format BLAST search output should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accredited-memory",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -i INFASTA -r REFFASTA -b INBLAST\n",
      "                             [-g OUTGFF] [-o OUTFASTA] [-p PERCENTCOVER]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -i/--inFasta, -r/--refFasta, -b/--inBlast\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# Working on adapting python script\n",
    "# ??? Do I need to alter the shebang?\n",
    "# Need to update contact information? \n",
    "\n",
    "############### Script ###############\n",
    "\n",
    "# !/usr/bin/env python\n",
    "# Python 3.8.5\n",
    "# Requires biopython\n",
    "\n",
    "############### BLASTtoGFF_50percent.py ##################\n",
    "\n",
    "# Takes blast result of a query gene set against a reference genome and returns\n",
    "# gff coords and extracted reference region for hits > 50% the length of each query sequence.\n",
    "\n",
    "# Version 1. Megan McDonald, April 2015.\n",
    "# Contact Megan McDonald, megan.mcdonald@anu.edu.au\n",
    "\n",
    "# Version 2. Joseph C. Blackwell, January 2021.\n",
    "# Updated to python 3.8.5 from 2.7.5\n",
    "# Reformated to use 'with' keyword for exception handling\n",
    "# Contact Megan McDonald, megan.mcdonald@anu.edu.au\n",
    "\n",
    "############### Main ###############\n",
    "\n",
    "# Import modules\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import argparse\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from os.path import basename\n",
    "\n",
    "# Defining main function\n",
    "def main(inFasta=None, refFasta=None, inBlast=None, outGff=None, outFasta=None, percentCover=50):\n",
    "    \n",
    "    # Define unsepcified output gff files\n",
    "    if outGff is None:\n",
    "        inBase = basename(refFasta)\n",
    "        noExt  = os.path.splitext(inBase)[0]\n",
    "        outGff = noExt + '_output.gff'\n",
    "    \n",
    "    # Define unsepcified output fasta files\n",
    "    if outFasta is None:\n",
    "        inBase   = basename(refFasta)\n",
    "        noExt    = os.path.splitext(inBase)[0]\n",
    "        outFasta = noExt + '_output.ga'\n",
    "    \n",
    "    # Define minimum proportional cover\n",
    "    # Potential python 2 vs 3 conflict\n",
    "    propCover = percentCover / 100\n",
    "    \n",
    "    # Initialise denovo dictionary\n",
    "    denovo = {}\n",
    "    \n",
    "    # For each contig of the denovo assembly, store id and sequence\n",
    "    for seq_record in SeqIO.parse(refFasta, \"fasta\"):\n",
    "        denovo[seq_record.id]=str(seq_record.seq)\n",
    "    \n",
    "    # Initialise reference gene dictionary \n",
    "    refgene = {}\n",
    "    \n",
    "    # For each query against the denovo assembly, store query id and sequence\n",
    "    for seq_record in SeqIO.parse(inFasta, \"fasta\"):\n",
    "        refgene[seq_record.id]=str(seq_record.seq)\n",
    "    \n",
    "    # Specify the BLAST output file\n",
    "    with open(inBlast, 'r') as f:\n",
    "        reader = csv.reader(f, dialext = 'excel-tab')\n",
    "    \n",
    "    # Open the output files \n",
    "    # outGff integrates the isolate name species\n",
    "    # outFasta integrates the name species\n",
    "    with open(outGff, 'w') as gff_file, open(outFasta, 'w') as fasta_file:\n",
    "    \n",
    "        # Initalise old query\n",
    "        oldquery = ''\n",
    "\n",
    "        # ??? for row in reader? (need example/toy data; what format should come out of blast search?)\n",
    "        for row in reader:\n",
    "            # Set information from reader rows \n",
    "            query    = row[0]\n",
    "            subject  = row[1]\n",
    "            alignlen = row[3]\n",
    "            querylen = row[4]\n",
    "            qstart   = int(row[5])\n",
    "            qend     = int(row[6])\n",
    "            sstart   = int(row(8))\n",
    "            send     = int(row[9])\n",
    "\n",
    "            # if the query is equal to old query: discard\n",
    "            if str(oldquery) == str(query):\n",
    "                continue\n",
    "\n",
    "            # if the alignment length is smaller than X% of the query: discard\n",
    "            if int(alignlen) / int(querylen) <= propCover:\n",
    "                continue \n",
    "\n",
    "            elif sstart <= send:\n",
    "                gff_line   = \"%s\\t%s\\t%d\\t%d\" %(subject, query, sstart, send)\n",
    "                seq_denovo = \"%s\" %(denovo[subject][sstart:send+1])\n",
    "                # ??? any difference to just using str()\n",
    "\n",
    "            elif sstart >= send:\n",
    "                gff_line   = \"%s\\t%s\\t%d\\t%d\" %(subject, query, send, sstart)\n",
    "                seq_denovo = Seq(denovo[subject][send:sstart+1])\n",
    "                seq_denovo = str(seq_denovo.reverse_complement())\n",
    "\n",
    "            # write to outGff\n",
    "            gff_file.write(gff_line + '\\n')\n",
    "\n",
    "            # write to outFasta\n",
    "            fasta_name = \">%s__%s\" % (query,subject)\n",
    "            fasta_file.write(fasta_name + '\\n')\n",
    "            fasta_file.write(seq_denovo + '\\n')\n",
    "\n",
    "            oldquery = query\n",
    "\n",
    "\n",
    "# Argument handling \n",
    "# ??? what is this bit?\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    arg_parser = argparse.ArgumentParser(\n",
    "        \n",
    "        # update description \n",
    "        description = 'Takes blast result of a query gene set against a denovo assembled genome and returns \\\n",
    "        gff coords and extracted reference region for hits > 50% the length of each query sequence.')\n",
    "    \n",
    "    # Define arguments\n",
    "    arg_parser.add_argument(\"-i\", \"--inFasta\",      default=None, required=True, help=\"Path to fasta file containing query gene sequences\")\n",
    "    arg_parser.add_argument(\"-r\", \"--refFasta\",     default=None, required=True, help=\"Path to fasta file containing de novo assemble genome used as blast database\")\n",
    "    arg_parser.add_argument(\"-b\", \"--inBlast\",      default=None, required=True, help=\"Tab delimited blast result of query genes against reference genome\")\n",
    "    arg_parser.add_argument(\"-g\", \"--outGff\",       default=None, help=\"Path to gff output file\")\n",
    "    arg_parser.add_argument(\"-o\", \"--outFasta\",     default=None, help=\"Path to output fasta file\")\n",
    "    arg_parser.add_argument(\"-p\", \"--percentCover\", default=50, type=int, help=\"Minimum query coverage threshold for hit to be considered, given as int between 1 and 100, default 50\")\n",
    "    \n",
    "    # ??? what is this?\n",
    "    if len(sys.argv) == 1:\n",
    "        arg_parser.print_help()\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Parse arguments\n",
    "    args = arg_parser.parse_args()\n",
    "    \n",
    "    # Variable Definitions\n",
    "    inFasta       = args.inFasta\n",
    "    refFasta      = args.refFasta\n",
    "    inBlast       = args.inBlast\n",
    "    outGff        = args.outGff\n",
    "    outFasta      = args.outFasta\n",
    "    percentCover  = args.percentCover\n",
    "    \n",
    "    # Run main function with parsed arguments\n",
    "    main(inFasta, refFasta, inBlast, outGff, outFasta, percentCover)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-seattle",
   "metadata": {},
   "source": [
    "## 26-01-2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pointed-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-thomson",
   "metadata": {},
   "source": [
    "# 25-02-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "decreased-calgary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bob.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from os.path import basename\n",
    "\n",
    "basename(\"hello/bob.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
